# Stacked-grabs
基于Pytorch对运行环境搭建，选用VMRD数据集作为实验数据集，实现视觉操作关系推理，并可以获取场景下的操作关系树，ROI检测提取结构：使用Cascade R-CNN级联网络实现物体的目标检测，特征提取后通过抓取提议网络得到潜在ROIs，再进入级联网络中完成目标检测。抓取检测结构FCN：使用旋转矩形锚框预测物体的可行抓取框。将训练完成的模型算法移植到Kinova机械臂上，让机械臂完成对多个物体的抓取。

1、抓取检测与目标检测的矩形框大多是不一样的，目标检测矩形框只需要4个参数即可确定一个水平矩形，其中表示目标矩形框的中心点，而表示目标矩形框的水平宽度，表示目标矩形框的垂直高度。
对于抓取检测的矩形框而言，由于它需要预测出机器人抓取该物体时抓手的抓取方向，所以用向量描述抓取矩形框信息，其中表示抓取矩形框的中心点，和表示机械臂末端执行器的张开尺寸和宽度，表示机械臂末端执行器相对于水平轴的方向。研究表明使用该五维信息能够很好地描述抓取信息，并能把该向量映射到机器人空间中用来精确抓取指定物体，同时也降低了网络计算量。

2、多目标VMRD抓取数据集有31种不同种类的物体，里面有4683张RGB图片共包含17688个物体。不同的是，该多物体抓取数据集不仅会标注每张图片的抓取矩形框的真值，也会标注出图片中每个物体的种类和位置最后VMRD抓取数据集还标注了51530个目标对的抓取关系，对于每个目标对的抓取关系是通过“父结点”和“子结点”的规则进行标注。

3、首先在数据输入部分，通过深度相机采集到的图片作为抓取系统的输入，图片经过目标检测部分和抓取关系部分后，将会检测到图片中所有物体的位置以及种类，还会生成图片中每个物体之间的抓取关系，通过抓取关系可以生成一个抓取关系树。然后在抓取位置检测部分会生成所有物体最优抓取位置，机器人抓取系统会依据抓取关系树来执行抓取物体的先后顺序，避免在抓取过程破坏其它物体。当机器人确认指定目标后，机器人会通过坐标系变换，将图片中的像素位置变换成真实世界的具体位置，最后机械臂会依靠控制系统的运动规划准确地抓取到物体。

![20-2](https://user-images.githubusercontent.com/80105687/178430283-3b377162-904a-472b-b99c-c25d778e379e.jpg)
![15-1](https://user-images.githubusercontent.com/80105687/178430303-c5a67e78-2d57-4461-aafb-964bfae06f6f.jpg)
